{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa6f344f-2813-4c26-9f71-d03e027b4a9c",
   "metadata": {},
   "source": [
    "# Image Only Input Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d73f2750-eded-48f7-a5f0-9cedbde8761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io\n",
    "import torch\n",
    "from skimage import color\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import ast\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import cohen_kappa_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81219233-6fa5-4aca-aada-27cb5f44349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5019b7-a6bf-412f-9b8e-b77f93d19f12",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c89e7145-e141-4a62-bc2c-f958020e4044",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7eed5d-0418-4e19-bb96-214b30dd972c",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1f4f569-46a6-4c3f-acab-478f2e63b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FundusDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with filename information.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        left_img_name = os.path.join(self.root_dir, self.data_frame.iloc[idx, 3])\n",
    "        right_img_name = os.path.join(self.root_dir, self.data_frame.iloc[idx, 4])\n",
    "\n",
    "        left_image = io.imread(left_img_name)\n",
    "        right_image = io.imread(right_img_name)\n",
    "\n",
    "        if len(left_image.shape) > 2 and left_image.shape[2] == 4:\n",
    "            left_image = left_image[:, :, 0]\n",
    "        if len(right_image.shape) > 2 and right_image.shape[2] == 4:\n",
    "            right_image = right_image[:, :, 0]\n",
    "\n",
    "        if left_image.shape[-1] != 3:\n",
    "            left_image = np.repeat(left_image[:, :, np.newaxis], 3, axis=2)\n",
    "        if right_image.shape[-1] != 3:\n",
    "            right_image = np.repeat(right_image[:, :, np.newaxis], 3, axis=2)\n",
    "\n",
    "        image_class = self.data_frame.iloc[idx, -1]\n",
    "        image_class = ast.literal_eval(image_class)\n",
    "        image_class = torch.tensor(image_class, dtype=torch.int64)\n",
    "        one_hot_image_class = F.one_hot(image_class, num_classes=2).squeeze(0)\n",
    "\n",
    "        if self.transform:\n",
    "            left_image = self.transform(left_image)\n",
    "            right_image = self.transform(right_image)\n",
    "\n",
    "        if left_image.dim() == 2:\n",
    "            left_image = left_image.unsqueeze(0)\n",
    "        if right_image.dim() == 2:\n",
    "            right_image = right_image.unsqueeze(0)\n",
    "\n",
    "        sample = {'left_image': left_image, 'right_image': right_image, 'class': one_hot_image_class}\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6473f7c-996e-4e16-b501-1f416d49f3a8",
   "metadata": {},
   "source": [
    "## Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5030a63a-948b-4c8b-8326-b6e205a6a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set csv file paths\n",
    "train_info_path = r'./OIA-ODIR/Training Set/Annotation/training_annotation_filtered.csv'\n",
    "valid_info_path = r'./OIA-ODIR/Off-site Test Set/Annotation/validation_annotation_filtered.csv'\n",
    "test_info_path = r'./OIA-ODIR/On-site Test Set/Annotation/testing_annotation_filtered.csv'\n",
    "\n",
    "# Set root directory paths\n",
    "train_root_dir = r'./OIA-ODIR/Training Set/Images'\n",
    "valid_root_dir = r'./OIA-ODIR//Off-site Test Set/Images'\n",
    "test_root_dir = r'./OIA-ODIR/On-site Test Set/Images'\n",
    "\n",
    "# Transformed dataset for left and right fundus\n",
    "transformed_dataset = {\n",
    "    'train': FundusDataset(csv_file=train_info_path, root_dir=train_root_dir, transform=transform),\n",
    "    'validate': FundusDataset(csv_file=valid_info_path, root_dir=valid_root_dir, transform=transform),\n",
    "    'test': FundusDataset(csv_file=test_info_path, root_dir=test_root_dir, transform=transform)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a718c43-5d57-4d69-8b75-c1450713272a",
   "metadata": {},
   "source": [
    "## Model 1: Late Fusion (SUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e0e57b1-74b8-4f77-ad8a-808264903708",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LateFusionSUM_Resnet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LateFusionSUM_Resnet18, self).__init__()\n",
    "        self.resnet18 = models.resnet18(weights='DEFAULT')\n",
    "        num_features = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Identity()  # Remove the fully connected layer\n",
    "        self.fc = nn.Linear(num_features, 512)  # Fusion layer\n",
    "        self.classifiers = nn.ModuleList([nn.Linear(512, 2) for _ in range(8)])  # 8 classifiers for multi-label classification\n",
    "        \n",
    "    def forward(self, left, right):\n",
    "        left_features = self.resnet18(left)\n",
    "        right_features = self.resnet18(right)\n",
    "        fused_features = left_features + right_features  # Element-wise sum fusion\n",
    "        fused_features = self.fc(fused_features)\n",
    "        outputs = [classifier(fused_features) for classifier in self.classifiers]\n",
    "        # predictions = [torch.sigmoid(output) for output in outputs]  # Sigmoid activation for multi-label classification\n",
    "        return torch.stack(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468c76bc-5e5f-4ef8-9636-5d34043556e4",
   "metadata": {},
   "source": [
    "## Model 2: Late Fusion (CONCAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efc59e75-1ae8-4d37-845a-c77e0c6ea1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LateFusionCONCAT_Resnet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LateFusionCONCAT_Resnet18, self).__init__()\n",
    "        self.resnet18 = models.resnet18(weights='DEFAULT')\n",
    "        num_features = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Identity()  # Remove the fully connected layer\n",
    "        self.fc = nn.Linear(num_features * 2, 512)  # Fusion layer\n",
    "        self.classifiers = nn.ModuleList([nn.Linear(512, 2) for _ in range(8)])  # 8 classifiers for multi-label classification\n",
    "        \n",
    "    def forward(self, left, right):\n",
    "        left_features = self.resnet18(left)\n",
    "        right_features = self.resnet18(right)\n",
    "        fused_features = torch.cat((left_features, right_features), dim=1)  # concat features late fusion\n",
    "        fused_features = self.fc(fused_features)\n",
    "        outputs = [classifier(fused_features) for classifier in self.classifiers]\n",
    "        return torch.stack(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc8c86d-d3a0-4285-b475-aae3025b9a7a",
   "metadata": {},
   "source": [
    "## Model 3: Late Fusion (PROD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8e60081-b2c7-444b-9036-5761f1322f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LateFusionPROD_Resnet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LateFusionPROD_Resnet18, self).__init__()\n",
    "        self.resnet18 = models.resnet18(weights='DEFAULT')\n",
    "        num_features = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Identity()  # Remove the fully connected layer\n",
    "        self.fc = nn.Linear(num_features, 512)  # Fusion layer\n",
    "        self.classifiers = nn.ModuleList([nn.Linear(512, 2) for _ in range(8)])  # 8 classifiers for multi-label classification\n",
    "        \n",
    "    def forward(self, left, right):\n",
    "        left_features = self.resnet18(left)\n",
    "        right_features = self.resnet18(right)\n",
    "        fused_features = left_features * right_features  # Element-wise product fusion\n",
    "        fused_features = self.fc(fused_features)\n",
    "        outputs = [classifier(fused_features) for classifier in self.classifiers]\n",
    "        return torch.stack(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0969a21e-75ac-4d2b-b8e3-cf64b7984a25",
   "metadata": {},
   "source": [
    "## Model 4: Early Fusion (SUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18594e91-8d82-4e98-bd45-01ee7d0a70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyFusionSUM_Resnet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EarlyFusionSUM_Resnet18, self).__init__()\n",
    "        self.resnet18 = models.resnet18(weights='DEFAULT')\n",
    "        num_features = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Identity()  # Remove the fully connected layer\n",
    "        self.fc = nn.Linear(num_features, 512)  # Fusion layer\n",
    "        self.classifiers = nn.ModuleList([nn.Linear(512, 2) for _ in range(8)])  # 8 classifiers for multi-label classification\n",
    "        \n",
    "    def forward(self, left, right):\n",
    "        summed_input = left + right\n",
    "        fused_features = self.resnet18(summed_input)\n",
    "        fused_features = self.fc(fused_features)\n",
    "        outputs = [classifier(fused_features) for classifier in self.classifiers]\n",
    "        return torch.stack(outputs, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5848b1-ef44-43c3-a025-800e0df2fb92",
   "metadata": {},
   "source": [
    "## Model 5: Early Fusion (CONCAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb9223e3-368b-4740-911b-ac9f73974e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyFusionCONCAT_Resnet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EarlyFusionCONCAT_Resnet18, self).__init__()\n",
    "        self.resnet18 = models.resnet18(weights='DEFAULT')\n",
    "        self.resnet18.conv1 = nn.Conv2d(6, 64, kernel_size=7, stride=2, padding=3, bias=False) # To accomodate concat early fusion\n",
    "        num_features = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Identity()\n",
    "        self.fc = nn.Linear(num_features, 512)\n",
    "        self.classifiers = nn.ModuleList([nn.Linear(512, 2) for _ in range(8)])  # 8 classifiers for multi-label classification\n",
    "        \n",
    "    def forward(self, left, right):\n",
    "        fused_input = torch.cat((left, right), dim=1)\n",
    "        fused_features = self.resnet18(fused_input)\n",
    "        fused_features = self.fc(fused_features)\n",
    "        outputs = [classifier(fused_features) for classifier in self.classifiers]\n",
    "        return torch.stack(outputs, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f1e767-7900-4a6a-9a82-7d4e353679a0",
   "metadata": {},
   "source": [
    "## Model 6: Early Fusion (PROD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a3e0ec8-2ddb-4e76-bc9e-d85645bb875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyFusionPROD_Resnet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EarlyFusionPROD_Resnet18, self).__init__()\n",
    "        self.resnet18 = models.resnet18(weights='DEFAULT')\n",
    "        num_features = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Identity()\n",
    "        self.fc = nn.Linear(num_features, 512)\n",
    "        self.classifiers = nn.ModuleList([nn.Linear(512, 2) for _ in range(8)])  # 8 classifiers for multi-label classification\n",
    "        \n",
    "    def forward(self, left, right):\n",
    "        fused_input = left * right # Element-wise multiplication of left and right images\n",
    "        fused_features = self.resnet18(fused_input)\n",
    "        fused_features = self.fc(fused_features)\n",
    "        outputs = [classifier(fused_features) for classifier in self.classifiers]\n",
    "        return torch.stack(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75e3fe-da9f-4564-ad4c-6a2f115ded33",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fec019fb-034a-484f-ac31-d8bd279c8d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "def train_model(model, dataloader, optimizer, criterion, num_epochs=10, verbose=True, save_path=None):\n",
    "    acc_dict = {'train':[],'validate':[],'test':[]}\n",
    "    loss_dict = {'train':[],'validate':[],'test':[]}\n",
    "    kappa_dict = {'validate': [],'test':[]}\n",
    "    f1_dict = {'validate': [],'test':[]}\n",
    "    auc_dict = {'validate': [],'test':[]}\n",
    "    best_loss = float('inf')\n",
    "    best_f1 = 0\n",
    "    best_kappa = 0\n",
    "    best_auc = 0\n",
    "    phases = ['train','validate','test']\n",
    "    since = time.time()\n",
    "    for i in range(num_epochs):\n",
    "        epoch_since = time.time()\n",
    "        print('-'*10)\n",
    "        print('Epoch: {}/{}'.format(i+1, num_epochs))\n",
    "        print('-'*10)\n",
    "        for p in phases:\n",
    "            running_correct = 0\n",
    "            running_loss = 0\n",
    "            running_total = 0\n",
    "            if p == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            all_probabilities_pos = []\n",
    "            all_predictions = []\n",
    "            all_labels = []\n",
    "            all_labels_pos = []\n",
    "\n",
    "            for data in dataloader[p]:\n",
    "                optimizer.zero_grad()\n",
    "                left_images = data['left_image'].to(device)\n",
    "                right_images = data['right_image'].to(device)\n",
    "                labels = data['class'].to(device)\n",
    "                outputs = model(left_images, right_images)\n",
    "                num_classifiers = outputs.size(1)\n",
    "                classifier_losses = []\n",
    "                epoch_loss = 0 \n",
    "                for j in range(num_classifiers):\n",
    "                    classifier_outputs = outputs[:, j, :]\n",
    "                    classifier_labels = labels[:, j, :].squeeze(dim=1)  # Squeeze extra dimension\n",
    "                    classifier_loss = criterion(classifier_outputs, classifier_labels.float())\n",
    "                    classifier_losses.append(classifier_loss)\n",
    "                \n",
    "                loss = sum(classifier_losses)\n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "                probabilities = torch.sigmoid(outputs)\n",
    "                probabilities_pos = probabilities[:, 1]\n",
    "                \n",
    "                labels_pos = labels[:, 1]\n",
    "                \n",
    "                predictions = (probabilities > 0.5).int()\n",
    "                \n",
    "                all_probabilities_pos.extend(probabilities_pos.cpu().detach().numpy())\n",
    "                all_predictions.extend(predictions.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_labels_pos.extend(labels_pos.cpu().numpy())\n",
    "                \n",
    "                running_correct += torch.sum(predictions == labels).item()\n",
    "                running_loss += loss.item()\n",
    "                running_total += labels.size(0)\n",
    "                if p== 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "            epoch_acc = float(running_correct/running_total)\n",
    "            epoch_loss = float(running_loss/running_total)\n",
    "            \n",
    "            \n",
    "            if verbose or (i%10 == 0):\n",
    "                print('Phase:{}, epoch loss: {:.4f}'.format(p, epoch_loss))\n",
    "            acc_dict[p].append(epoch_acc)\n",
    "            loss_dict[p].append(epoch_loss)\n",
    "            \n",
    "            if p == 'validate':\n",
    "                all_labels_flat = np.concatenate(all_labels).flatten()\n",
    "                all_predictions_flat = np.concatenate(all_predictions).flatten()\n",
    "                all_labels_pos_flat = np.concatenate(all_labels_pos).flatten()\n",
    "                all_probabilities_pos_flat = np.concatenate(all_probabilities_pos).flatten()\n",
    "                \n",
    "                kappa = cohen_kappa_score(all_labels_flat, all_predictions_flat)\n",
    "                f1 = f1_score(all_labels_flat, all_predictions_flat, average='macro')\n",
    "                auc = roc_auc_score(all_labels_pos, all_probabilities_pos) # macro\n",
    "                \n",
    "                print('Kappa: {:.4f} F1: {:.4f} AUC: {:.4f}'.format(kappa, f1, auc))\n",
    "                \n",
    "                kappa_dict[p].append(kappa)\n",
    "                f1_dict[p].append(f1)\n",
    "                auc_dict[p].append(auc)\n",
    "\n",
    "                if f1 > best_f1:\n",
    "                    best_f1 = f1\n",
    "                    best_model_wts = deepcopy(model.state_dict())\n",
    "                    best_epoch = i+1\n",
    "                    best_kappa = kappa\n",
    "                    best_auc = auc\n",
    "                    \n",
    "            if p == 'test':\n",
    "                all_labels_flat = np.concatenate(all_labels).flatten()\n",
    "                all_predictions_flat = np.concatenate(all_predictions).flatten()\n",
    "                all_labels_pos_flat = np.concatenate(all_labels_pos).flatten()\n",
    "                all_probabilities_pos_flat = np.concatenate(all_probabilities_pos).flatten()\n",
    "                \n",
    "                kappa = cohen_kappa_score(all_labels_flat, all_predictions_flat)\n",
    "                f1 = f1_score(all_labels_flat, all_predictions_flat, average='macro')\n",
    "                auc = roc_auc_score(all_labels_pos, all_probabilities_pos)\n",
    "                \n",
    "                print('Kappa: {:.4f} F1: {:.4f} AUC: {:.4f}'.format(kappa, f1, auc))\n",
    "                \n",
    "                kappa_dict[p].append(kappa)\n",
    "                f1_dict[p].append(f1)\n",
    "                auc_dict[p].append(auc)\n",
    "                    \n",
    "        if save_path:\n",
    "            torch.save(best_model_wts, save_path.format(round(best_f1, 4)))\n",
    "        epoch_time_elapsed = time.time() - epoch_since\n",
    "        print('Epoch complete in {:.0f}m {:.0f}s'.format(epoch_time_elapsed // 60, epoch_time_elapsed % 60))\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('-'*10)\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best Val F1: {:4f} at Epoch {}'.format(best_f1, best_epoch))\n",
    "    print('Corresponding Kappa: {:4f} and AUC: {:4f}'.format(best_kappa, best_auc))\n",
    "\n",
    "    return acc_dict, loss_dict, kappa_dict, f1_dict, auc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bd853a-ccb9-45fe-ab7c-481d2198b212",
   "metadata": {},
   "source": [
    "## BS = 16, LR = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4878045-a5ef-4fd7-beb4-ba31225be615",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "lr = 0.00001\n",
    "\n",
    "# Load data for left and right fundus\n",
    "dataloader = {x: DataLoader(transformed_dataset[x], batch_size=bs, shuffle=True) for x in ['train', 'validate','test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f50afddf-2358-439a-ae4e-1cc206d675c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch: 1/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1985\n",
      "Phase:validate, epoch loss: 0.1634\n",
      "Kappa: 0.7114 F1: 0.8557 AUC: 0.7101\n",
      "Phase:test, epoch loss: 0.1643\n",
      "Kappa: 0.7098 F1: 0.8549 AUC: 0.6679\n",
      "Epoch complete in 12m 32s\n",
      "----------\n",
      "Epoch: 2/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1525\n",
      "Phase:validate, epoch loss: 0.1556\n",
      "Kappa: 0.7278 F1: 0.8639 AUC: 0.7352\n",
      "Phase:test, epoch loss: 0.1567\n",
      "Kappa: 0.7177 F1: 0.8589 AUC: 0.6943\n",
      "Epoch complete in 10m 15s\n",
      "----------\n",
      "Epoch: 3/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1411\n",
      "Phase:validate, epoch loss: 0.1519\n",
      "Kappa: 0.7293 F1: 0.8646 AUC: 0.7584\n",
      "Phase:test, epoch loss: 0.1542\n",
      "Kappa: 0.7195 F1: 0.8598 AUC: 0.7206\n",
      "Epoch complete in 9m 54s\n",
      "----------\n",
      "Epoch: 4/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1321\n",
      "Phase:validate, epoch loss: 0.1509\n",
      "Kappa: 0.7369 F1: 0.8684 AUC: 0.7705\n",
      "Phase:test, epoch loss: 0.1535\n",
      "Kappa: 0.7240 F1: 0.8620 AUC: 0.7298\n",
      "Epoch complete in 10m 14s\n",
      "----------\n",
      "Epoch: 5/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1239\n",
      "Phase:validate, epoch loss: 0.1522\n",
      "Kappa: 0.7311 F1: 0.8655 AUC: 0.7752\n",
      "Phase:test, epoch loss: 0.1569\n",
      "Kappa: 0.7211 F1: 0.8606 AUC: 0.7308\n",
      "Epoch complete in 10m 31s\n",
      "----------\n",
      "Epoch: 6/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1145\n",
      "Phase:validate, epoch loss: 0.1546\n",
      "Kappa: 0.7298 F1: 0.8649 AUC: 0.7660\n",
      "Phase:test, epoch loss: 0.1596\n",
      "Kappa: 0.7234 F1: 0.8617 AUC: 0.7311\n",
      "Epoch complete in 10m 13s\n",
      "----------\n",
      "Epoch: 7/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1042\n",
      "Phase:validate, epoch loss: 0.1516\n",
      "Kappa: 0.7326 F1: 0.8663 AUC: 0.7638\n",
      "Phase:test, epoch loss: 0.1536\n",
      "Kappa: 0.7293 F1: 0.8647 AUC: 0.7328\n",
      "Epoch complete in 9m 59s\n",
      "----------\n",
      "Epoch: 8/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.0923\n",
      "Phase:validate, epoch loss: 0.1572\n",
      "Kappa: 0.7331 F1: 0.8665 AUC: 0.7518\n",
      "Phase:test, epoch loss: 0.1627\n",
      "Kappa: 0.7193 F1: 0.8596 AUC: 0.7213\n",
      "Epoch complete in 10m 8s\n",
      "----------\n",
      "Epoch: 9/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.0814\n",
      "Phase:validate, epoch loss: 0.1604\n",
      "Kappa: 0.7270 F1: 0.8635 AUC: 0.7580\n",
      "Phase:test, epoch loss: 0.1632\n",
      "Kappa: 0.7165 F1: 0.8582 AUC: 0.7236\n",
      "Epoch complete in 10m 35s\n",
      "----------\n",
      "Epoch: 10/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.0691\n",
      "Phase:validate, epoch loss: 0.1682\n",
      "Kappa: 0.7225 F1: 0.8612 AUC: 0.7322\n",
      "Phase:test, epoch loss: 0.1678\n",
      "Kappa: 0.7227 F1: 0.8613 AUC: 0.7120\n",
      "Epoch complete in 11m 12s\n",
      "----------\n",
      "Training complete in 105m 33s\n",
      "Best Val F1: 0.868434 at Epoch 4\n",
      "Corresponding Kappa: 0.736869 and AUC: 0.770457\n"
     ]
    }
   ],
   "source": [
    "lfs_model = LateFusionSUM_Resnet18()\n",
    "lfs_model.to(device)\n",
    "save_path = \"./saved_models/bs_16_lr_1e-05/LFS_F1_{}.pt\"\n",
    "file_path = \"./saved_results/bs_16_lr_1e-05/LFS_results.pkl\"\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(lfs_model.parameters(), lr=lr)\n",
    "lfs_results = []\n",
    "acc_dict, loss_dict, kappa_dict, f1_dict, auc_dict = train_model(lfs_model, dataloader, optimizer, criterion, num_epochs=10, save_path=save_path)\n",
    "lfs_results.append((acc_dict, loss_dict, kappa_dict, f1_dict, auc_dict))\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(lfs_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d06d22b5-c225-4f0a-98c5-cbccdfdb3a11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch: 1/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.2025\n",
      "Phase:validate, epoch loss: 0.1660\n",
      "Kappa: 0.7068 F1: 0.8534 AUC: 0.6811\n",
      "Phase:test, epoch loss: 0.1667\n",
      "Kappa: 0.7138 F1: 0.8569 AUC: 0.6494\n",
      "Epoch complete in 9m 26s\n",
      "----------\n",
      "Epoch: 2/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1563\n",
      "Phase:validate, epoch loss: 0.1555\n",
      "Kappa: 0.7174 F1: 0.8587 AUC: 0.7217\n",
      "Phase:test, epoch loss: 0.1566\n",
      "Kappa: 0.7210 F1: 0.8605 AUC: 0.6861\n",
      "Epoch complete in 9m 6s\n",
      "----------\n",
      "Epoch: 3/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1446\n",
      "Phase:validate, epoch loss: 0.1516\n",
      "Kappa: 0.7225 F1: 0.8612 AUC: 0.7367\n",
      "Phase:test, epoch loss: 0.1533\n",
      "Kappa: 0.7206 F1: 0.8603 AUC: 0.6961\n",
      "Epoch complete in 8m 57s\n",
      "----------\n",
      "Epoch: 4/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1355\n",
      "Phase:validate, epoch loss: 0.1502\n",
      "Kappa: 0.7220 F1: 0.8610 AUC: 0.7573\n",
      "Phase:test, epoch loss: 0.1523\n",
      "Kappa: 0.7251 F1: 0.8625 AUC: 0.7027\n",
      "Epoch complete in 8m 53s\n",
      "----------\n",
      "Epoch: 5/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1257\n",
      "Phase:validate, epoch loss: 0.1501\n",
      "Kappa: 0.7321 F1: 0.8660 AUC: 0.7661\n",
      "Phase:test, epoch loss: 0.1530\n",
      "Kappa: 0.7234 F1: 0.8617 AUC: 0.7115\n",
      "Epoch complete in 9m 17s\n",
      "----------\n",
      "Epoch: 6/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1168\n",
      "Phase:validate, epoch loss: 0.1531\n",
      "Kappa: 0.7253 F1: 0.8626 AUC: 0.7519\n",
      "Phase:test, epoch loss: 0.1549\n",
      "Kappa: 0.7216 F1: 0.8608 AUC: 0.7053\n",
      "Epoch complete in 8m 49s\n",
      "----------\n",
      "Epoch: 7/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1064\n",
      "Phase:validate, epoch loss: 0.1542\n",
      "Kappa: 0.7255 F1: 0.8628 AUC: 0.7288\n",
      "Phase:test, epoch loss: 0.1569\n",
      "Kappa: 0.7145 F1: 0.8572 AUC: 0.6881\n",
      "Epoch complete in 8m 51s\n",
      "----------\n",
      "Epoch: 8/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.0948\n",
      "Phase:validate, epoch loss: 0.1594\n",
      "Kappa: 0.7189 F1: 0.8595 AUC: 0.7315\n",
      "Phase:test, epoch loss: 0.1613\n",
      "Kappa: 0.7119 F1: 0.8560 AUC: 0.6970\n",
      "Epoch complete in 8m 37s\n",
      "----------\n",
      "Epoch: 9/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.0824\n",
      "Phase:validate, epoch loss: 0.1645\n",
      "Kappa: 0.7164 F1: 0.8582 AUC: 0.7221\n",
      "Phase:test, epoch loss: 0.1656\n",
      "Kappa: 0.7152 F1: 0.8576 AUC: 0.6835\n",
      "Epoch complete in 8m 1s\n",
      "----------\n",
      "Epoch: 10/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.0709\n",
      "Phase:validate, epoch loss: 0.1695\n",
      "Kappa: 0.7101 F1: 0.8551 AUC: 0.7054\n",
      "Phase:test, epoch loss: 0.1692\n",
      "Kappa: 0.7126 F1: 0.8563 AUC: 0.6746\n",
      "Epoch complete in 8m 1s\n",
      "----------\n",
      "Training complete in 87m 56s\n",
      "Best Val F1: 0.866034 at Epoch 5\n",
      "Corresponding Kappa: 0.732071 and AUC: 0.766063\n"
     ]
    }
   ],
   "source": [
    "lfc_model = LateFusionCONCAT_Resnet18()\n",
    "lfc_model.to(device)\n",
    "save_path = \"./saved_models/bs_16_lr_1e-05/LFC_F1_{}.pt\"\n",
    "file_path = \"./saved_results/bs_16_lr_1e-05/LFC_results.pkl\"\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(lfc_model.parameters(), lr=lr)\n",
    "lfc_results = []\n",
    "acc_dict, loss_dict, kappa_dict, f1_dict, auc_dict = train_model(lfc_model, dataloader, optimizer, criterion, num_epochs=10, save_path=save_path)\n",
    "lfc_results.append((acc_dict, loss_dict, kappa_dict, f1_dict, auc_dict))\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(lfc_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89cb4ad2-c2d6-471a-9ad3-2533e1ec236f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch: 1/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.2253\n",
      "Phase:validate, epoch loss: 0.1759\n",
      "Kappa: 0.7053 F1: 0.8527 AUC: 0.6568\n",
      "Phase:test, epoch loss: 0.1784\n",
      "Kappa: 0.7015 F1: 0.8507 AUC: 0.6235\n",
      "Epoch complete in 11m 30s\n",
      "----------\n",
      "Epoch: 2/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1588\n",
      "Phase:validate, epoch loss: 0.1630\n",
      "Kappa: 0.7134 F1: 0.8567 AUC: 0.7007\n",
      "Phase:test, epoch loss: 0.1665\n",
      "Kappa: 0.7089 F1: 0.8545 AUC: 0.6677\n",
      "Epoch complete in 9m 2s\n",
      "----------\n",
      "Epoch: 3/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1445\n",
      "Phase:validate, epoch loss: 0.1584\n",
      "Kappa: 0.7146 F1: 0.8573 AUC: 0.7322\n",
      "Phase:test, epoch loss: 0.1615\n",
      "Kappa: 0.7126 F1: 0.8563 AUC: 0.6940\n",
      "Epoch complete in 8m 59s\n",
      "----------\n",
      "Epoch: 4/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1347\n",
      "Phase:validate, epoch loss: 0.1590\n",
      "Kappa: 0.7189 F1: 0.8595 AUC: 0.7398\n",
      "Phase:test, epoch loss: 0.1632\n",
      "Kappa: 0.7117 F1: 0.8558 AUC: 0.6976\n",
      "Epoch complete in 8m 17s\n",
      "----------\n",
      "Epoch: 5/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1264\n",
      "Phase:validate, epoch loss: 0.1605\n",
      "Kappa: 0.7172 F1: 0.8586 AUC: 0.7519\n",
      "Phase:test, epoch loss: 0.1653\n",
      "Kappa: 0.7082 F1: 0.8541 AUC: 0.7070\n",
      "Epoch complete in 9m 15s\n",
      "----------\n",
      "Epoch: 6/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1175\n",
      "Phase:validate, epoch loss: 0.1604\n",
      "Kappa: 0.7210 F1: 0.8605 AUC: 0.7526\n",
      "Phase:test, epoch loss: 0.1667\n",
      "Kappa: 0.7147 F1: 0.8574 AUC: 0.7120\n",
      "Epoch complete in 9m 2s\n",
      "----------\n",
      "Epoch: 7/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1079\n",
      "Phase:validate, epoch loss: 0.1583\n",
      "Kappa: 0.7245 F1: 0.8622 AUC: 0.7480\n",
      "Phase:test, epoch loss: 0.1614\n",
      "Kappa: 0.7146 F1: 0.8573 AUC: 0.7094\n",
      "Epoch complete in 9m 26s\n",
      "----------\n",
      "Epoch: 8/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.0979\n",
      "Phase:validate, epoch loss: 0.1626\n",
      "Kappa: 0.7240 F1: 0.8620 AUC: 0.7355\n",
      "Phase:test, epoch loss: 0.1683\n",
      "Kappa: 0.7130 F1: 0.8565 AUC: 0.7118\n",
      "Epoch complete in 9m 54s\n",
      "----------\n",
      "Epoch: 9/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.0889\n",
      "Phase:validate, epoch loss: 0.1662\n",
      "Kappa: 0.7220 F1: 0.8610 AUC: 0.7497\n",
      "Phase:test, epoch loss: 0.1689\n",
      "Kappa: 0.7124 F1: 0.8562 AUC: 0.7165\n",
      "Epoch complete in 9m 35s\n",
      "----------\n",
      "Epoch: 10/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.0783\n",
      "Phase:validate, epoch loss: 0.1718\n",
      "Kappa: 0.7154 F1: 0.8577 AUC: 0.7386\n",
      "Phase:test, epoch loss: 0.1744\n",
      "Kappa: 0.7103 F1: 0.8552 AUC: 0.7069\n",
      "Epoch complete in 9m 17s\n",
      "----------\n",
      "Training complete in 94m 18s\n",
      "Best Val F1: 0.862247 at Epoch 7\n",
      "Corresponding Kappa: 0.724495 and AUC: 0.747976\n"
     ]
    }
   ],
   "source": [
    "lfp_model = LateFusionPROD_Resnet18()\n",
    "lfp_model.to(device)\n",
    "save_path = \"./saved_models/bs_16_lr_1e-05/LFP_F1_{}.pt\"\n",
    "file_path = \"./saved_results/bs_16_lr_1e-05/LFP_results.pkl\"\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(lfp_model.parameters(), lr=lr)\n",
    "lfp_results = []\n",
    "acc_dict, loss_dict, kappa_dict, f1_dict, auc_dict = train_model(lfp_model, dataloader, optimizer, criterion, num_epochs=10, save_path=save_path)\n",
    "lfp_results.append((acc_dict, loss_dict, kappa_dict, f1_dict, auc_dict))\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(lfp_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a15dc26-c7be-4eb6-b1b6-d8bbeab74590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch: 1/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.2211\n",
      "Phase:validate, epoch loss: 0.1740\n",
      "Kappa: 0.7093 F1: 0.8547 AUC: 0.6696\n",
      "Phase:test, epoch loss: 0.1745\n",
      "Kappa: 0.7089 F1: 0.8545 AUC: 0.6260\n",
      "Epoch complete in 9m 36s\n",
      "----------\n",
      "Epoch: 2/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1614\n",
      "Phase:validate, epoch loss: 0.1609\n",
      "Kappa: 0.7152 F1: 0.8576 AUC: 0.7120\n",
      "Phase:test, epoch loss: 0.1614\n",
      "Kappa: 0.7131 F1: 0.8565 AUC: 0.6592\n",
      "Epoch complete in 10m 1s\n",
      "----------\n",
      "Epoch: 3/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1487\n",
      "Phase:validate, epoch loss: 0.1578\n",
      "Kappa: 0.7217 F1: 0.8609 AUC: 0.7311\n",
      "Phase:test, epoch loss: 0.1585\n",
      "Kappa: 0.7159 F1: 0.8579 AUC: 0.6807\n",
      "Epoch complete in 9m 29s\n",
      "----------\n",
      "Epoch: 4/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1401\n",
      "Phase:validate, epoch loss: 0.1552\n",
      "Kappa: 0.7217 F1: 0.8609 AUC: 0.7497\n",
      "Phase:test, epoch loss: 0.1575\n",
      "Kappa: 0.7119 F1: 0.8560 AUC: 0.6873\n",
      "Epoch complete in 9m 25s\n",
      "----------\n",
      "Epoch: 5/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1321\n",
      "Phase:validate, epoch loss: 0.1565\n",
      "Kappa: 0.7192 F1: 0.8596 AUC: 0.7572\n",
      "Phase:test, epoch loss: 0.1609\n",
      "Kappa: 0.7054 F1: 0.8527 AUC: 0.6923\n",
      "Epoch complete in 9m 58s\n",
      "----------\n",
      "Epoch: 6/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1228\n",
      "Phase:validate, epoch loss: 0.1586\n",
      "Kappa: 0.7146 F1: 0.8573 AUC: 0.7576\n",
      "Phase:test, epoch loss: 0.1622\n",
      "Kappa: 0.7064 F1: 0.8532 AUC: 0.6880\n",
      "Epoch complete in 11m 2s\n",
      "----------\n",
      "Epoch: 7/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1122\n",
      "Phase:validate, epoch loss: 0.1592\n",
      "Kappa: 0.7199 F1: 0.8600 AUC: 0.7537\n",
      "Phase:test, epoch loss: 0.1640\n",
      "Kappa: 0.7025 F1: 0.8512 AUC: 0.6842\n",
      "Epoch complete in 10m 55s\n",
      "----------\n",
      "Epoch: 8/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1001\n",
      "Phase:validate, epoch loss: 0.1641\n",
      "Kappa: 0.7124 F1: 0.8562 AUC: 0.7392\n",
      "Phase:test, epoch loss: 0.1723\n",
      "Kappa: 0.6928 F1: 0.8464 AUC: 0.6800\n",
      "Epoch complete in 10m 26s\n",
      "----------\n",
      "Epoch: 9/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.0886\n",
      "Phase:validate, epoch loss: 0.1695\n",
      "Kappa: 0.7199 F1: 0.8600 AUC: 0.7216\n",
      "Phase:test, epoch loss: 0.1769\n",
      "Kappa: 0.6970 F1: 0.8485 AUC: 0.6659\n",
      "Epoch complete in 10m 48s\n",
      "----------\n",
      "Epoch: 10/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.0772\n",
      "Phase:validate, epoch loss: 0.1766\n",
      "Kappa: 0.7144 F1: 0.8572 AUC: 0.7297\n",
      "Phase:test, epoch loss: 0.1846\n",
      "Kappa: 0.6988 F1: 0.8494 AUC: 0.6721\n",
      "Epoch complete in 11m 32s\n",
      "----------\n",
      "Training complete in 103m 12s\n",
      "Best Val F1: 0.860859 at Epoch 4\n",
      "Corresponding Kappa: 0.721717 and AUC: 0.749720\n"
     ]
    }
   ],
   "source": [
    "efs_model = EarlyFusionSUM_Resnet18()\n",
    "efs_model.to(device)\n",
    "save_path = \"./saved_models/bs_16_lr_1e-05/EFS_F1_{}.pt\"\n",
    "file_path = \"./saved_results/bs_16_lr_1e-05/EFS_results.pkl\"\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(efs_model.parameters(), lr=lr)\n",
    "efs_results = []\n",
    "acc_dict, loss_dict, kappa_dict, f1_dict, auc_dict = train_model(efs_model, dataloader, optimizer, criterion, num_epochs=10, save_path=save_path)\n",
    "efs_results.append((acc_dict, loss_dict, kappa_dict, f1_dict, auc_dict))\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(efs_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c66f619b-6598-4090-a2a2-abd91496dd59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch: 1/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.2235\n",
      "Phase:validate, epoch loss: 0.1784\n",
      "Kappa: 0.7121 F1: 0.8561 AUC: 0.6097\n",
      "Phase:test, epoch loss: 0.1784\n",
      "Kappa: 0.7082 F1: 0.8541 AUC: 0.6019\n",
      "Epoch complete in 11m 5s\n",
      "----------\n",
      "Epoch: 2/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1671\n",
      "Phase:validate, epoch loss: 0.1691\n",
      "Kappa: 0.7119 F1: 0.8559 AUC: 0.6657\n",
      "Phase:test, epoch loss: 0.1688\n",
      "Kappa: 0.7077 F1: 0.8538 AUC: 0.6345\n",
      "Epoch complete in 9m 40s\n",
      "----------\n",
      "Epoch: 3/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1576\n",
      "Phase:validate, epoch loss: 0.1650\n",
      "Kappa: 0.7111 F1: 0.8556 AUC: 0.6974\n",
      "Phase:test, epoch loss: 0.1643\n",
      "Kappa: 0.7088 F1: 0.8544 AUC: 0.6522\n",
      "Epoch complete in 9m 49s\n",
      "----------\n",
      "Epoch: 4/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1504\n",
      "Phase:validate, epoch loss: 0.1623\n",
      "Kappa: 0.7154 F1: 0.8577 AUC: 0.7160\n",
      "Phase:test, epoch loss: 0.1632\n",
      "Kappa: 0.7123 F1: 0.8562 AUC: 0.6603\n",
      "Epoch complete in 9m 58s\n",
      "----------\n",
      "Epoch: 5/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1442\n",
      "Phase:validate, epoch loss: 0.1622\n",
      "Kappa: 0.7152 F1: 0.8576 AUC: 0.7257\n",
      "Phase:test, epoch loss: 0.1628\n",
      "Kappa: 0.7089 F1: 0.8545 AUC: 0.6540\n",
      "Epoch complete in 9m 38s\n",
      "----------\n",
      "Epoch: 6/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1379\n",
      "Phase:validate, epoch loss: 0.1638\n",
      "Kappa: 0.7086 F1: 0.8543 AUC: 0.7210\n",
      "Phase:test, epoch loss: 0.1634\n",
      "Kappa: 0.7072 F1: 0.8536 AUC: 0.6470\n",
      "Epoch complete in 9m 50s\n",
      "----------\n",
      "Epoch: 7/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1303\n",
      "Phase:validate, epoch loss: 0.1668\n",
      "Kappa: 0.7035 F1: 0.8518 AUC: 0.7219\n",
      "Phase:test, epoch loss: 0.1674\n",
      "Kappa: 0.7048 F1: 0.8524 AUC: 0.6543\n",
      "Epoch complete in 9m 57s\n",
      "----------\n",
      "Epoch: 8/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1224\n",
      "Phase:validate, epoch loss: 0.1689\n",
      "Kappa: 0.7051 F1: 0.8525 AUC: 0.7173\n",
      "Phase:test, epoch loss: 0.1695\n",
      "Kappa: 0.7026 F1: 0.8513 AUC: 0.6460\n",
      "Epoch complete in 10m 28s\n",
      "----------\n",
      "Epoch: 9/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1141\n",
      "Phase:validate, epoch loss: 0.1761\n",
      "Kappa: 0.6967 F1: 0.8484 AUC: 0.7121\n",
      "Phase:test, epoch loss: 0.1771\n",
      "Kappa: 0.6939 F1: 0.8470 AUC: 0.6456\n",
      "Epoch complete in 12m 22s\n",
      "----------\n",
      "Epoch: 10/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1060\n",
      "Phase:validate, epoch loss: 0.1745\n",
      "Kappa: 0.6952 F1: 0.8476 AUC: 0.6934\n",
      "Phase:test, epoch loss: 0.1776\n",
      "Kappa: 0.6947 F1: 0.8473 AUC: 0.6264\n",
      "Epoch complete in 12m 47s\n",
      "----------\n",
      "Training complete in 105m 35s\n",
      "Best Val F1: 0.857702 at Epoch 4\n",
      "Corresponding Kappa: 0.715404 and AUC: 0.716035\n"
     ]
    }
   ],
   "source": [
    "efc_model = EarlyFusionCONCAT_Resnet18()\n",
    "efc_model.to(device)\n",
    "save_path = \"./saved_models/bs_16_lr_1e-05/EFC_F1_{}.pt\"\n",
    "file_path = \"./saved_results/bs_16_lr_1e-05/EFC_results.pkl\"\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(efc_model.parameters(), lr=lr)\n",
    "efc_results = []\n",
    "acc_dict, loss_dict, kappa_dict, f1_dict, auc_dict = train_model(efc_model, dataloader, optimizer, criterion, num_epochs=10, save_path=save_path)\n",
    "efc_results.append((acc_dict, loss_dict, kappa_dict, f1_dict, auc_dict))\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(efc_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b53a6e71-7578-4476-b5c3-ddc19a60e4d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch: 1/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.2221\n",
      "Phase:validate, epoch loss: 0.1774\n",
      "Kappa: 0.7116 F1: 0.8558 AUC: 0.6443\n",
      "Phase:test, epoch loss: 0.1768\n",
      "Kappa: 0.7082 F1: 0.8541 AUC: 0.5890\n",
      "Epoch complete in 12m 25s\n",
      "----------\n",
      "Epoch: 2/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1641\n",
      "Phase:validate, epoch loss: 0.1652\n",
      "Kappa: 0.7119 F1: 0.8559 AUC: 0.6816\n",
      "Phase:test, epoch loss: 0.1644\n",
      "Kappa: 0.7094 F1: 0.8547 AUC: 0.6228\n",
      "Epoch complete in 10m 15s\n",
      "----------\n",
      "Epoch: 3/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1520\n",
      "Phase:validate, epoch loss: 0.1612\n",
      "Kappa: 0.7141 F1: 0.8571 AUC: 0.6992\n",
      "Phase:test, epoch loss: 0.1609\n",
      "Kappa: 0.7106 F1: 0.8553 AUC: 0.6436\n",
      "Epoch complete in 9m 54s\n",
      "----------\n",
      "Epoch: 4/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1440\n",
      "Phase:validate, epoch loss: 0.1584\n",
      "Kappa: 0.7184 F1: 0.8592 AUC: 0.7186\n",
      "Phase:test, epoch loss: 0.1605\n",
      "Kappa: 0.7089 F1: 0.8545 AUC: 0.6519\n",
      "Epoch complete in 10m 14s\n",
      "----------\n",
      "Epoch: 5/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1356\n",
      "Phase:validate, epoch loss: 0.1592\n",
      "Kappa: 0.7237 F1: 0.8619 AUC: 0.7260\n",
      "Phase:test, epoch loss: 0.1643\n",
      "Kappa: 0.6992 F1: 0.8496 AUC: 0.6458\n",
      "Epoch complete in 10m 31s\n",
      "----------\n",
      "Epoch: 6/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1260\n",
      "Phase:validate, epoch loss: 0.1604\n",
      "Kappa: 0.7210 F1: 0.8605 AUC: 0.7218\n",
      "Phase:test, epoch loss: 0.1667\n",
      "Kappa: 0.7005 F1: 0.8502 AUC: 0.6321\n",
      "Epoch complete in 10m 13s\n",
      "----------\n",
      "Epoch: 7/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1158\n",
      "Phase:validate, epoch loss: 0.1605\n",
      "Kappa: 0.7199 F1: 0.8600 AUC: 0.7179\n",
      "Phase:test, epoch loss: 0.1679\n",
      "Kappa: 0.6990 F1: 0.8495 AUC: 0.6345\n",
      "Epoch complete in 9m 59s\n",
      "----------\n",
      "Epoch: 8/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.1049\n",
      "Phase:validate, epoch loss: 0.1649\n",
      "Kappa: 0.7192 F1: 0.8596 AUC: 0.7134\n",
      "Phase:test, epoch loss: 0.1737\n",
      "Kappa: 0.6865 F1: 0.8432 AUC: 0.6365\n",
      "Epoch complete in 10m 8s\n",
      "----------\n",
      "Epoch: 9/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.0919\n",
      "Phase:validate, epoch loss: 0.1733\n",
      "Kappa: 0.7182 F1: 0.8591 AUC: 0.7127\n",
      "Phase:test, epoch loss: 0.1815\n",
      "Kappa: 0.6869 F1: 0.8434 AUC: 0.6268\n",
      "Epoch complete in 10m 35s\n",
      "----------\n",
      "Epoch: 10/10\n",
      "----------\n",
      "Phase:train, epoch loss: 0.0816\n",
      "Phase:validate, epoch loss: 0.1795\n",
      "Kappa: 0.7093 F1: 0.8547 AUC: 0.6847\n",
      "Phase:test, epoch loss: 0.1873\n",
      "Kappa: 0.6862 F1: 0.8431 AUC: 0.6127\n",
      "Epoch complete in 11m 12s\n",
      "----------\n",
      "Training complete in 105m 26s\n",
      "Best Val F1: 0.861868 at Epoch 5\n",
      "Corresponding Kappa: 0.723737 and AUC: 0.725951\n"
     ]
    }
   ],
   "source": [
    "efp_model = EarlyFusionPROD_Resnet18()\n",
    "efp_model.to(device)\n",
    "save_path = \"./saved_models/bs_16_lr_1e-05/EFP_F1_{}.pt\"\n",
    "file_path = \"./saved_results/bs_16_lr_1e-05/EFP_results.pkl\"\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(efp_model.parameters(), lr=lr)\n",
    "efp_results = []\n",
    "acc_dict, loss_dict, kappa_dict, f1_dict, auc_dict = train_model(efp_model, dataloader, optimizer, criterion, num_epochs=10, save_path=save_path)\n",
    "efp_results.append((acc_dict, loss_dict, kappa_dict, f1_dict, auc_dict))\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(efp_results, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4med_env",
   "language": "python",
   "name": "dl4med_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
