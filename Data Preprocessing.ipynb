{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5451e397-de2d-4e2b-a686-18d58a390a4a",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a333e5a-2497-4946-9e92-f0e9dd7d91ab",
   "metadata": {},
   "source": [
    "Dataset link: https://github.com/nkicsl/OIA-ODIR?tab=readme-ov-file\n",
    "\n",
    "Original Data Information:\n",
    "\n",
    "A structured ophthalmic database of 5,000 patients with age, color fundus photographs from left and right eyes and doctors' diagnostic keywords from doctors (in short, ODIR). This dataset is ‘‘real-life’’ set of patient information collected by Shanggong Medical Technology Co., Ltd. from different hospitals/medical centers in China. In these institutions, fundus images are captured by various cameras in the market, such as Canon, Zeiss and Kowa, resulting into varied image resolutions. Patient identifying information will be removed. Annotations are labeled by trained human readers with quality control management. They classify patient into eight labels including normal (N), diabetes (D), glaucoma (G), cataract (C), AMD (A), hypertension (H), myopia (M) and other diseases/abnormalities (O) based on both eye images and additionally patient age."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ceecd3-378a-406f-b1a6-916a9bcb9fa7",
   "metadata": {},
   "source": [
    "## Image-Only Input Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eac3a2e-5bd8-4b69-b2ad-5e41afaab113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io\n",
    "import torch\n",
    "from skimage import color\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import ast\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import cohen_kappa_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3413fe75-b6a1-4790-a44c-6643e5689416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size:  3500\n",
      "Validation Set Size:  500\n",
      "Test Set Size:  1000\n"
     ]
    }
   ],
   "source": [
    "# Load dataframes for train, validation and test set\n",
    "train_info = pd.read_csv(r'./OIA-ODIR/Training Set/Annotation/training annotation (English).csv')\n",
    "valid_info = pd.read_csv(r'./OIA-ODIR/Off-site Test Set/Annotation/off-site test annotation (English).csv')\n",
    "test_info = pd.read_csv(r'./OIA-ODIR/On-site Test Set/Annotation/on-site test annotation (English).csv')\n",
    "\n",
    "print('Training Set Size: ', len(train_info))\n",
    "print('Validation Set Size: ', len(valid_info))\n",
    "print('Test Set Size: ', len(test_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daf30900-a2bd-4227-a784-f8762bd0070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Classifications to Binary Vector\n",
    "class_columns = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n",
    "train_info['Label'] = train_info[class_columns].apply(lambda row: row.to_numpy().tolist(), axis=1)\n",
    "valid_info['Label'] = valid_info[class_columns].apply(lambda row: row.to_numpy().tolist(), axis=1)\n",
    "test_info['Label'] = test_info[class_columns].apply(lambda row: row.to_numpy().tolist(), axis=1)\n",
    "\n",
    "# Drop Diagnostic Keywords\n",
    "train_info = train_info.drop(columns=['Left-Diagnostic Keywords', 'Right-Diagnostic Keywords'])\n",
    "valid_info = valid_info.drop(columns=['Left-Diagnostic Keywords', 'Right-Diagnostic Keywords'])\n",
    "test_info = test_info.drop(columns=['Left-Diagnostic Keywords', 'Right-Diagnostic Keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d141ed-9b95-4c15-b3aa-3933da8f80f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          N     D    G    C    A    H    M    O\n",
      "Train  1140  1128  215  212  164  103  174  979\n",
      "Valid   162   163   32   31   25   16   23  136\n",
      "Test    324   327   58   65   49   30   46  275\n"
     ]
    }
   ],
   "source": [
    "# Class EDA\n",
    "class_counts_df = pd.DataFrame(columns=class_columns, index=['Train', 'Valid', 'Test'])\n",
    "\n",
    "for c in class_columns:\n",
    "    class_counts_df.loc['Train', c] = np.sum(train_info[c])\n",
    "    class_counts_df.loc['Valid', c] = np.sum(valid_info[c])\n",
    "    class_counts_df.loc['Test', c] = np.sum(test_info[c])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(class_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea9077eb-7e42-407c-b9be-297c2e315dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Instances with 3 classes: 29\n",
      "Valid - Instances with 3 classes: 5\n",
      "Test - Instances with 3 classes: 8\n"
     ]
    }
   ],
   "source": [
    "train_three_class_count = sum(np.sum(label) >= 3 for label in train_info['Label'])\n",
    "print(\"Train - Instances with 3 classes:\", train_three_class_count)\n",
    "\n",
    "valid_three_class_count = sum(np.sum(label) >= 3 for label in valid_info['Label'])\n",
    "print(\"Valid - Instances with 3 classes:\", valid_three_class_count)\n",
    "\n",
    "test_three_class_count = sum(np.sum(label) >= 3 for label in test_info['Label'])\n",
    "print(\"Test - Instances with 3 classes:\", test_three_class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a16a81d9-76e9-46d3-9517-5a8449818ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop instances with 3 classes or more\n",
    "train_indices_to_drop = [idx for idx, label in enumerate(train_info['Label']) if np.sum(label) >= 3]\n",
    "train_info_filtered = train_info.drop(train_indices_to_drop)\n",
    "train_info_filtered = train_info_filtered.reset_index(drop=True)\n",
    "\n",
    "valid_indices_to_drop = [idx for idx, label in enumerate(valid_info['Label']) if np.sum(label) >= 3]\n",
    "valid_info_filtered = valid_info.drop(valid_indices_to_drop)\n",
    "valid_info_filtered = valid_info_filtered.reset_index(drop=True)\n",
    "\n",
    "test_indices_to_drop = [idx for idx, label in enumerate(test_info['Label']) if np.sum(label) >= 3]\n",
    "test_info_filtered = test_info.drop(test_indices_to_drop)\n",
    "test_info_filtered = test_info_filtered.reset_index(drop=True)\n",
    "\n",
    "# Save new dfs\n",
    "train_info_filtered.to_csv(r'./OIA-ODIR/Training Set/Annotation/training_annotation_filtered.csv', index=False)\n",
    "valid_info_filtered.to_csv(r'./OIA-ODIR/Off-site Test Set/Annotation/validation_annotation_filtered.csv', index=False)\n",
    "test_info_filtered.to_csv(r'./OIA-ODIR/On-site Test Set/Annotation/testing_annotation_filtered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27863f27-7a74-48d2-bc28-a99efcad64ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          N     D    G    C    A   H    M    O\n",
      "Train  1140  1105  200  203  161  99  168  952\n",
      "Valid   162   160   30   30   22  15   23  131\n",
      "Test    324   320   56   63   45  27   46  269\n"
     ]
    }
   ],
   "source": [
    "# Class EDA post 3 class instance drop\n",
    "class_counts_df = pd.DataFrame(columns=class_columns, index=['Train', 'Valid', 'Test'])\n",
    "\n",
    "for c in class_columns:\n",
    "    class_counts_df.loc['Train', c] = np.sum(train_info_filtered[c])\n",
    "    class_counts_df.loc['Valid', c] = np.sum(valid_info_filtered[c])\n",
    "    class_counts_df.loc['Test', c] = np.sum(test_info_filtered[c])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(class_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "469a29bb-d996-4dfb-91a0-d0560aab20e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set csv file paths\n",
    "train_info_path = r'./OIA-ODIR/Training Set/Annotation/training_annotation_filtered.csv'\n",
    "valid_info_path = r'./OIA-ODIR/Off-site Test Set/Annotation/validation_annotation_filtered.csv'\n",
    "test_info_path = r'./OIA-ODIR/On-site Test Set/Annotation/testing_annotation_filtered.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f78110d9-a943-4184-bb92-d40e4e43c2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Train subset:  173\n",
      "Length of Validation subset:  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-45773832/ipykernel_141981/960317742.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train_subset = train_df.groupby('Label', group_keys=False).apply(lambda x: x.sample(frac=subset_ratio, random_state=42))\n",
      "/state/partition1/job-45773832/ipykernel_141981/960317742.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  valid_subset = valid_df.groupby('Label', group_keys=False).apply(lambda x: x.sample(frac=subset_ratio, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "# Create random subset for hyperparameter tuning\n",
    "train_df = pd.read_csv(train_info_path)\n",
    "valid_df = pd.read_csv(valid_info_path)\n",
    "subset_ratio = 0.05\n",
    "\n",
    "train_subset = train_df.groupby('Label', group_keys=False).apply(lambda x: x.sample(frac=subset_ratio, random_state=42))\n",
    "valid_subset = valid_df.groupby('Label', group_keys=False).apply(lambda x: x.sample(frac=subset_ratio, random_state=42))\n",
    "\n",
    "print('Length of Train subset: ', len(train_subset))\n",
    "print('Length of Validation subset: ', len(valid_subset))\n",
    "\n",
    "train_subset.to_csv(r\"./OIA-ODIR/Training Set/Annotation/train_subset.csv\", index=False)\n",
    "valid_subset.to_csv(r\"./OIA-ODIR/Off-site Test Set/Annotation/valid_subset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947115cd-a9b0-4845-abbc-e82a27058e41",
   "metadata": {},
   "source": [
    "## Image + Tabular Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c7f4f98-c5f4-4089-b2e2-1fc0d6fd752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = r'./OIA-ODIR/Training Set/Annotation/training_annotation_filtered.csv'\n",
    "valid = r'./OIA-ODIR/Off-site Test Set/Annotation/validation_annotation_filtered.csv'\n",
    "test = r'./OIA-ODIR/On-site Test Set/Annotation/testing_annotation_filtered.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d95afc90-26b8-41c4-99a6-81134c9abdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "Patient Sex\n",
      "Male      1869\n",
      "Female    1602\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation:\n",
      "Patient Sex\n",
      "Male      266\n",
      "Female    229\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test:\n",
      "Patient Sex\n",
      "Male      532\n",
      "Female    460\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(train)\n",
    "valid_df = pd.read_csv(valid)\n",
    "test_df = pd.read_csv(test)\n",
    "\n",
    "print('Train:')\n",
    "print(train_df['Patient Sex'].value_counts())\n",
    "print()\n",
    "print('Validation:')\n",
    "print(valid_df['Patient Sex'].value_counts())\n",
    "print()\n",
    "print('Test:')\n",
    "print(test_df['Patient Sex'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bcd5aa3-c4cd-4c59-9f80-a413f060f05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Sex</th>\n",
       "      <th>Left-Fundus</th>\n",
       "      <th>Right-Fundus</th>\n",
       "      <th>N</th>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0_left.jpg</td>\n",
       "      <td>0_right.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1_left.jpg</td>\n",
       "      <td>1_right.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>2_left.jpg</td>\n",
       "      <td>2_right.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>3_left.jpg</td>\n",
       "      <td>3_right.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>4_left.jpg</td>\n",
       "      <td>4_right.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>4686</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>4686_left.jpg</td>\n",
       "      <td>4686_right.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>4688</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>4688_left.jpg</td>\n",
       "      <td>4688_right.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>4689</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>4689_left.jpg</td>\n",
       "      <td>4689_right.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3469</th>\n",
       "      <td>4690</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>4690_left.jpg</td>\n",
       "      <td>4690_right.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>4784</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>4784_left.jpg</td>\n",
       "      <td>4784_right.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3471 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Patient Age  Patient Sex    Left-Fundus    Right-Fundus  N  D  G  \\\n",
       "0        0           69            0     0_left.jpg     0_right.jpg  0  0  0   \n",
       "1        1           57            1     1_left.jpg     1_right.jpg  1  0  0   \n",
       "2        2           42            1     2_left.jpg     2_right.jpg  0  1  0   \n",
       "3        3           66            1     3_left.jpg     3_right.jpg  0  0  0   \n",
       "4        4           53            1     4_left.jpg     4_right.jpg  0  1  0   \n",
       "...    ...          ...          ...            ...             ... .. .. ..   \n",
       "3466  4686           63            1  4686_left.jpg  4686_right.jpg  0  1  0   \n",
       "3467  4688           42            1  4688_left.jpg  4688_right.jpg  0  1  0   \n",
       "3468  4689           54            1  4689_left.jpg  4689_right.jpg  0  1  0   \n",
       "3469  4690           57            1  4690_left.jpg  4690_right.jpg  0  1  0   \n",
       "3470  4784           58            1  4784_left.jpg  4784_right.jpg  0  0  0   \n",
       "\n",
       "      C  A  H  M  O                     Label  \n",
       "0     1  0  0  0  0  [0, 0, 0, 1, 0, 0, 0, 0]  \n",
       "1     0  0  0  0  0  [1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2     0  0  0  0  1  [0, 1, 0, 0, 0, 0, 0, 1]  \n",
       "3     0  0  0  0  1  [0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "4     0  0  0  0  1  [0, 1, 0, 0, 0, 0, 0, 1]  \n",
       "...  .. .. .. .. ..                       ...  \n",
       "3466  0  0  0  0  0  [0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "3467  0  0  0  0  0  [0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "3468  0  0  0  0  0  [0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "3469  0  0  0  0  0  [0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "3470  0  1  1  0  0  [0, 0, 0, 0, 1, 1, 0, 0]  \n",
       "\n",
       "[3471 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 = Female, 1 = Male\n",
    "train_df['Patient Sex'] = pd.get_dummies(train_df['Patient Sex'], drop_first=True).astype(int)\n",
    "valid_df['Patient Sex'] = pd.get_dummies(valid_df['Patient Sex'], drop_first=True).astype(int)\n",
    "test_df['Patient Sex'] = pd.get_dummies(test_df['Patient Sex'], drop_first=True).astype(int)\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bc72812-933a-47b4-8300-b97564b67207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new csv: one hot encoded - OHE\n",
    "train_df.to_csv(r'./OIA-ODIR/Training Set/Annotation/training_annotation_filtered_OHE.csv', index=False)\n",
    "valid_df.to_csv(r'./OIA-ODIR/Off-site Test Set/Annotation/validation_annotation_filtered_OHE.csv', index=False)\n",
    "test_df.to_csv(r'./OIA-ODIR/On-site Test Set/Annotation/testing_annotation_filtered_OHE.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50441ebd-1569-411b-a461-8c10565207b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4med_env",
   "language": "python",
   "name": "dl4med_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
